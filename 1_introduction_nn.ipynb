{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0b02df97-cbb3-4759-9371-cbbecd0ccd86"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Construyendo una red neuronal con PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "03d05899-7ff9-4413-aa67-c7a96bbdfcde"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "fa44eec5-93b3-4e4b-adcb-1065bb5cc474"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cargando los datos del CIFAR10\n",
    "\n",
    "- El conjunto de datos a utilizar es el **[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)**.\n",
    "- Es un conjunto estándar para hacer *reconocimiento de imágenes*.\n",
    "- Buscamos entrenar un clasificador que reconozca que está siendo mostrado en la imagen de un conjunto fijo de categorías posibles.\n",
    "- El CIFAR-10 está compuesto por imágenes a color de 32x32 píxeles representadas como tensores de 32x32x3, donde la tercera dimensión representa el *channel* (i.e. el color en RGB). Los valores representan la intensidad de cada color en dicho pixel.\n",
    "- La salida son 10 clases: avión, auto, pájaro, gato, siervo, perro, sapo, caballo, bote, camión.\n",
    "- La librería `torchvision` nos facilita obtener el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "CIFAR_CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "                 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "BATCH_SIZE = 128  # For mini-batch gradient descent\n",
    "EPOCHS = 2\n",
    "\n",
    "# This is to normalize from PILImage to Torch Tensors in range [-1, 1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Explorando el CIFAR-10\n",
    "\n",
    "Vamos a explorar algunas de las imágenes que muestra el conjunto de datos del CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # desnormalizar\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(numpy.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# obtener algunas imágenes de entrenamiento\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images[:5]\n",
    "labels = labels[:5]\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print('\\t'.join('%5s' % CIFAR_CLASSES[labels[j]] for j in range(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contruyendo la red neuronal\n",
    "\n",
    "- Comenzaremos por construir un *perceptrón multicapa* que es la red neuronal más común.\n",
    "- La capa más básica es la *lineal* (i.e. la completamente conectada) que se define en [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html).\n",
    "    - Internamente tiene dos tensores: una matriz de pesos y un vector de biases. PyTorch nos abstrae de eso.\n",
    "    - Es equivalente a la capa [`Dense`](https://keras.io/api/layers/core_layers/dense/) en [Keras](https://keras.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Modelo Secuencial\n",
    "\n",
    "El mayor tipo de abstracción lo provee [`torch.nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html). Es un modelo donde cada capa se aplica después de la siguiente. Es limitado en sus usos posibles, pero tiene la ventaja de abstraer completamente del funcionamiento. Es equivalente al modelo [`tf.keras.Sequential`](https://keras.io/api/models/sequential/#sequential-class) de Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(32 * 32 * 3, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Podemos inspeccionar el modelo simplemente imprimiéndolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Podemos ver que nos devuelve el modelo inicializado al azar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "img_check, lbl_check = dataiter.next()\n",
    "img_check, lbl_check = img_check[0], lbl_check[0]\n",
    "img_check = img_check.view(-1)  # Transformar la imagen en un vector, es equivalente a img_check.view(32*32*3)\n",
    "\n",
    "print(f\"Clase real: {CIFAR_CLASSES[lbl_check]}\")\n",
    "print(f\"Clase devuelta: {CIFAR_CLASSES[model(img_check).argmax().item()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Modelo de PyTorch\n",
    "\n",
    "Es el modelo base de PyTorch que permite un grado de personalización mucho más profundo. \n",
    "\n",
    "Los modelos en PyTorch heredan de la clase [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module). La clase posee dos métodos que requieren definirse:\n",
    "1. `__init__`: Define la estructura de la red (i.e las capas que tiene).\n",
    "2. `forward`: Define como interactúan las capas de la red (i.e. las operaciones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer1 = nn.Linear(32 * 32 * 3, 512)\n",
    "        self.hidden_layer2 = nn.Linear(512, 256)\n",
    "        self.output_layer = nn.Linear(256, 10)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.hidden_layer1(x)  # Go through hidden layer\n",
    "        x = F.relu(x)  # Activation Function\n",
    "        x = self.hidden_layer2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.output_layer(x)  # Output Layer\n",
    "        return x\n",
    "\n",
    "model = MLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Podemos inspeccionar el modelo simplemente imprimiéndolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Podemos ver que nos devuelve el modelo inicializado al azar (notar que este modelo no requiere reordenar la matriz que representa la imagen):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "img_check, lbl_check = dataiter.next()\n",
    "img_check, lbl_check = img_check[0], lbl_check[0]\n",
    "\n",
    "print(f\"Clase real: {CIFAR_CLASSES[lbl_check]}\")\n",
    "print(f\"Clase devuelta: {CIFAR_CLASSES[model(img_check.view(-1)).argmax().item()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Funciones de Activación\n",
    "\n",
    "- Una red neuronal con activación lineal no tiene mucho más poder de representación que un algoritmo lineal.\n",
    "- Para expresar no linearidad en la red neuronal se necesitan funciones no lineales de activación.\n",
    "- Una función de activación común es la *sigmoide* (o logística).\n",
    "- PyTorch soporta varias funciones de activación: rectified linea unit (ReLU), tangenge hiperbólica, sigmoide \"dura\", etc.\n",
    "    - Hoy en día, por sus propiedades, ReLU suele ser la más utilizada [1].\n",
    "- La función de activación *Softmax* suele utilizarse al final de una red de multiples clases, tiene como objetivo transformar un vector de *scores* en un vector probabilístico.\n",
    "    - Si bien solía ser muy común en las primeras versiones de muchos frameworks de deep learning, con el tiempo se dejó de utilizar y se incluye directamente en la función de costo de manera transparente al usuario.\n",
    "- En PyTorch la mayoría de estas funciones se definen en el módulo [`torch.nn.functional`](https://pytorch.org/docs/stable/nn.functional.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"margin:auto;width:100%;\" src=\"images/activation_functions.png\" alt=\"Funciones de activación\" title=\"Funciones de activación\"/>\n",
    "<div style=\"text-align:right;font-size:0.75em;\">Fuente: <a href=\"https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/\" target=\"_blank\">https://ujjwalkarn.me/2016/08/09/quick-intro-neural-networks/</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(32 * 32 * 3, 512),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(512, 10),\n",
    "    nn.Softmax(-1)\n",
    ")\n",
    "\n",
    "print(model(img_check.view(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preparando el modelo para entrenarlo\n",
    "\n",
    "- Para minimizar una red neuronal necesitamos *calcular sus gradientes*.\n",
    "    - Esto se hace con el algoritmo de *retropropagación*.\n",
    "- PyTorch tiene la capacidad de hacerlo automáticamente.\n",
    "    - Esto se conoce como _diferenciación automática_ y es algo común en los frameworks de deep learning.\n",
    "- Necesitaremos definir dos puntos para entrenar un modelo: la función de costo y el algoritmo de optimización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Función de costo\n",
    "\n",
    "- La función de costo puede cambiar de acuerdo al tipo de problema (clasificación binaria/multiclase o regresión).\n",
    "    - La funciones más comunes son la media del error cuadrático (_mean squared error_) para regresión y la entropía cruzada (_crossentropy_) para clasificación.\n",
    "    - Las funciones de costo necesitan ser diferenciables, las más comunes ya están implementadas (con sus respectivas derivadas) en PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Algoritmo de optimización\n",
    "\n",
    "- El algoritmo de optimización es el que entrena la red. Existen varios, que en si son variaciones del algoritmo de _descenso por la gradiente_.\n",
    "    - El módulo [`torch.optim`](https://pytorch.org/docs/stable/optim.html) tiene implementados varios algoritmos de optimización muy utilizados en aprendizaje automático.\n",
    "\n",
    "<div style=\"text-align: center; margin: 5px 0;\">\n",
    "    <div style=\"display: inline-block;\">\n",
    "        <img src=\"images/contours_evaluation_optimizers.gif\" alt=\"Optimización\" style=\"width:350px;\"/>\n",
    "    </div>\n",
    "    <div style=\"display: inline-block;\">\n",
    "        <img src=\"images/saddle_point_evaluation_optimizers.gif\" alt=\"Optimización\" style=\"width:350px;\"/>\n",
    "    </div>\n",
    "</div>\n",
    "<div style=\"text-align:right;font-size:0.75em;\">Fuente: <a href=\"http://ruder.io/optimizing-gradient-descent/\" target=\"_blank\">http://ruder.io/optimizing-gradient-descent/</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Entrenamiento\n",
    "\n",
    "- Ya teniendo todos los parámetros definidos, el modelo está listo para entrenarse.\n",
    "- PyTorch no provee una solución \"out-of-the-box\" para el bucle de entrenamiento (o en inglés *training loop*), a diferencia de scikit-learn y Keras que proveen `fit` y `predict`. Existen algunas librerías que proveen dicha abstracción, pero dejamos como ejercicio [buscar alguna](https://pytorch.org/ecosystem/) si lo consideran necesario.\n",
    "- En general si bien el hecho de tener que hacer el loop de entrenamiento desde cero es un poco tedioso, da lugar a mucha más personalización y control del proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(trainloader)\n",
    "    for i, data in enumerate(pbar, 1):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs.view(inputs.shape[0], -1))\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i > 0 and i % 50 == 0:    # print every 50 mini-batches\n",
    "            pbar.set_description(f\"[{epoch + 1}, {i}] loss: {running_loss / 50:.4g}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Guardar el modelo\n",
    "\n",
    "Guardamos los parámetros del modelo entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./data/cifar-model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluación\n",
    "\n",
    "### Evaluación Manual\n",
    "\n",
    "Podemos ver como funciona el modelo luego de un ciclo de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images, labels = images[:5], labels[:5]\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images.view(images.shape[0], -1)))\n",
    "print('GroundTruth: ', ' '.join('%5s' % CIFAR_CLASSES[labels[j]] for j in range(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Cargamos los pesos del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "model.load_state_dict(torch.load(\"./data/cifar-model.pth\"))\n",
    "model.eval();  # Activate evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Vemos como está funcionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % CIFAR_CLASSES[predicted[j]] for j in range(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Evaluación General\n",
    "\n",
    "Si queremos medir que tan bien está funcionando en general, necesitamos correr para todos los valores de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(testloader):\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs.view(inputs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predicted.numpy())\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=CIFAR_CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Entrenamiento en GPU\n",
    "\n",
    "El entrenamiento en GPU requiere que \"enviemos\" el modelo y los datos al GPU. Para ello, se deben cambiar algunas cosas.\n",
    "\n",
    "### Definir el dispositivo\n",
    "\n",
    "Primero se define el dispositivo a utilizar. Si se dispone de GPU lo utilizamos, en caso contrario se selecciona el CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Una vez seleccionado el dispositivo, debemos crear y enviar el modelo a dicho dispositivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "model.to(device)\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "De aqui los pasos son prácticamente los mismos que para el [entrenamiento](#Entrenamiento). Es importante que definamos nuevamente el algoritmo de optimización sobre los parámetros nuevos que en este caso se enviaron al GPU. Luego, durante el *training loop* debemos asegurarnos de, previo a pasar los datos al modelo, estos sean cargados en el dispositivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(tqdm(trainloader), 1):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # run the rest of the algorithm as usual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regularización de la red\n",
    "\n",
    "### Regularización de los pesos\n",
    "\n",
    "- La red puede regularizarse penalizando los pesos.\n",
    "- Los pesos se regularizan mediante alguna norma:\n",
    "    - L1 es la suma del valor absoluto: ${\\displaystyle \\lambda \\sum_{i=1}^{k} |w_i|}$\n",
    "    - L2 es la suma del valor cuadrado, es la más común: ${\\displaystyle \\lambda \\sum_{i=1}^{k} w_i^2}$\n",
    "    - Elastic net es una combinación de ambas: ${\\displaystyle \\lambda_1 \\sum_{i=1}^{k} |w_i| + \\lambda_2 \\sum_{i=1}^{k} w_i^2}$\n",
    "- Para un análisis detallado de la diferencia entre L1 y L2 revisar [\\[2\\]](http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Varios (sino todos) de los algoritmos de optimización implementados en `torch.optim` vienen con una implementación de la norma L2 para regularización (que suele ser la norma por defecto), simplemente se debe seleccionar el valor de $\\lambda$ que viene representado por el parámetro `weight_decay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=0.001,\n",
    "                       weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Si queremos mayor control (e.g. implementar una versión de L1 o ElasticNet), debemos hacerlo como parte del *training loop*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "l1_lambda = 0.001\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "for inputs, labels in tqdm(trainloader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs.view(inputs.shape[0], -1))\n",
    "    loss = loss_function(outputs, labels)\n",
    "\n",
    "    l1_reg = torch.tensor(0.).to(device)\n",
    "    for param in model.parameters():\n",
    "        l1_reg += torch.norm(param, p=1)\n",
    "    loss += l1_reg * l1_lambda\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "El caso anterior regulariza todos los pesos, i.e. los pesos de las capas y los bias. Si sólo queremos regularizar los pesos, se puede utilizar [`nn.Module.named_parameters`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.named_parameters) y filtrar aquellos parámetros que tengan `bias` en el nombre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "l1_reg = torch.tensor(0.)\n",
    "for param_name, param_weight in model.named_parameters():\n",
    "    if 'bias' not in param_name:\n",
    "        l1_reg += torch.norm(param, p=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dropout\n",
    "\n",
    "- Otra forma muy usada a la hora de regularizar es el **dropout** [3].\n",
    "- Es extremadamente efectivo y simple.\n",
    "- Es complementario a L1/L2/ElasticNet.\n",
    "- Durante el entrenamiento se implementa apagando un neurón con alguna probabilidad **_p_** (un hiperparámetro)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img style=\"margin:auto;width:75%;\" src=\"images/dropout.jpeg\" alt=\"Dropout\" title=\"Dropout\"/>\n",
    "<div style=\"text-align:right;font-size:0.75em;\">Fuente: Trabajo de Srivastava et al. [3]</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dropout en PyTorch\n",
    "\n",
    "- Se aplica agregando capas al modelo.\n",
    "- Se llaman capas [`torch.nn.Dropout`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) y se agrega a cada capa que se quiere regularizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(32 * 32 * 3, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Linear(512, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Batch Normalization\n",
    "\n",
    "- En general, para acelerar la convergencia de la red, se normalizan los features de entrada, de manera que todos estén en un rango similar.\n",
    "- Esta idea también puede llevarse a las capas ocultas de la red.\n",
    "- La idea de la \"Normalización por Lotes\" (*Batch Normalization*) [4] es reducir el rango en el que se mueven los valores de las neuronas ocultas.\n",
    "- La manera en que se hace esto es restarle, a cada salida de cada capa oculta, la media del lote (batch) de datos de entrenamiento y dividirlo por la desviación estándar (a grandes razgos).\n",
    "- Como resultado, la red converge más rápido e incluso se genera un efecto de regularización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Batch Normalization en PyTorch\n",
    "\n",
    "- Se aplica agregando capas al modelo.\n",
    "- Se llaman capas [`BatchNorm*`](https://pytorch.org/docs/stable/nn.html#normalization-layers), donde `*` se reemplaza por las dimensiones de entrada (`1d`, `2d`, `3d`) y se agrega a cada capa que se quiere normalizar.\n",
    "- El `momentum` es un parámetro que decide cuánta información de los lotes anteriores se tiene en cuenta a la hora de normalizar el lote actual (en el trabajo original de *Batch Normalization*, este es de `0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(32 * 32 * 3, 512),\n",
    "    nn.BatchNorm1d(512, momentum=0.1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Linear(512, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Referencias\n",
    "\n",
    "- [1] LeCun, Yann, Bengio, Yoshua, and Hinton, Geoffrey. \"Deep learning.\" Nature 521, no. 7553 (2015): 436-444.\n",
    "- [2] \"Differences between L1 and L2 as Loss Function and Regularization\". http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/\n",
    "- [3] Srivastava, Nitish, Geoffrey E. Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. \"Dropout: a simple way to prevent neural networks from overfitting.\" Journal of machine learning research 15, no. 1 (2014): 1929-1958. Harvard.\n",
    "- [4] Ioffe, S., & Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
