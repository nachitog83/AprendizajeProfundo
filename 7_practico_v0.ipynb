{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "supreme-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gzip\n",
    "import csv\n",
    "import json\n",
    "import logging\n",
    "import mlflow\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.parsing import preprocessing\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s: %(levelname)s - %(message)s\",\n",
    "    level=logging.INFO\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "inappropriate-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadSequences:\n",
    "    def __init__(self, pad_value=0, max_length=None, min_length=1):\n",
    "        assert max_length is None or min_length <= max_length\n",
    "        self.pad_value = pad_value\n",
    "        self.max_length = max_length\n",
    "        self.min_length = min_length\n",
    "\n",
    "    def __call__(self, items):\n",
    "        data = [item[\"data\"] for item in items]\n",
    "        target = [item[\"target\"] for item in items]\n",
    "        seq_lengths = [len(d) for d in data]\n",
    "\n",
    "        if self.max_length:\n",
    "            max_length = self.max_length\n",
    "            seq_lengths = [min(self.max_length, l) for l in seq_lengths]\n",
    "        else:\n",
    "            max_length = max(self.min_length, max(seq_lengths))\n",
    "\n",
    "        data = [d[:l] + [self.pad_value] * (max_length - l)\n",
    "                for d, l in zip(data, seq_lengths)]\n",
    "\n",
    "        return {\n",
    "            \"data\": torch.LongTensor(data),\n",
    "            \"target\": torch.LongTensor(target)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "swedish-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeliChallengeDataset(IterableDataset):\n",
    "    def __init__(self,\n",
    "                 dataset_path,\n",
    "                 random_buffer_size=2048):\n",
    "        assert random_buffer_size > 0\n",
    "        self.dataset_path = dataset_path\n",
    "        self.random_buffer_size = random_buffer_size\n",
    "\n",
    "        with gzip.open(self.dataset_path, \"rt\") as dataset:\n",
    "            item = json.loads(next(dataset).strip())\n",
    "            self.n_labels = item[\"n_labels\"]\n",
    "            self.dataset_size = item[\"size\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        try:\n",
    "            with gzip.open(self.dataset_path, \"rt\") as dataset:\n",
    "                shuffle_buffer = []\n",
    "\n",
    "                for line in dataset:\n",
    "                    item = json.loads(line.strip())\n",
    "                    item = {\n",
    "                        \"data\": item[\"data\"],\n",
    "                        \"target\": item[\"target\"]\n",
    "                    }\n",
    "                    \n",
    "                    self.item = item\n",
    "\n",
    "                    if self.random_buffer_size == 1:\n",
    "                        yield item\n",
    "                    else:\n",
    "                        shuffle_buffer.append(item)\n",
    "\n",
    "                        if len(shuffle_buffer) == self.random_buffer_size:\n",
    "                            random.shuffle(shuffle_buffer)\n",
    "                            for item in shuffle_buffer:\n",
    "                                yield item\n",
    "                            shuffle_buffer = []\n",
    "\n",
    "                if len(shuffle_buffer) > 0:\n",
    "                    random.shuffle(shuffle_buffer)\n",
    "                    for item in shuffle_buffer:\n",
    "                        yield item\n",
    "        except GeneratorExit:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "anonymous-organizer",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 pretrained_embeddings_path,\n",
    "                 token_to_index,\n",
    "                 n_labels,\n",
    "                 hidden_layers=[256, 128],\n",
    "                 dropout=0.3,\n",
    "                 vector_size=300,\n",
    "                 freeze_embedings=True):\n",
    "        super().__init__()\n",
    "        with gzip.open(token_to_index, \"rt\") as fh:\n",
    "            token_to_index = json.load(fh)\n",
    "        embeddings_matrix = torch.randn(len(token_to_index), vector_size)\n",
    "        embeddings_matrix[0] = torch.zeros(vector_size)\n",
    "        with gzip.open(pretrained_embeddings_path, \"rt\") as fh:\n",
    "            next(fh)\n",
    "            for line in fh:\n",
    "                word, vector = line.strip().split(None, 1)\n",
    "                if word in token_to_index:\n",
    "                    embeddings_matrix[token_to_index[word]] =\\\n",
    "                        torch.FloatTensor([float(n) for n in vector.split()])\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n",
    "                                                       freeze=freeze_embedings,\n",
    "                                                       padding_idx=0)\n",
    "        self.hidden_layers = [\n",
    "            nn.Linear(vector_size, hidden_layers[0])\n",
    "        ]\n",
    "        for input_size, output_size in zip(hidden_layers[:-1], hidden_layers[1:]):\n",
    "            self.hidden_layers.append(\n",
    "                nn.Linear(input_size, output_size)\n",
    "            )\n",
    "        self.dropout = dropout\n",
    "        self.hidden_layers = nn.ModuleList(self.hidden_layers)\n",
    "        self.output = nn.Linear(hidden_layers[-1], n_labels)\n",
    "        self.vector_size = vector_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = torch.mean(x, dim=1)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            if self.dropout:\n",
    "                x = F.dropout(x, self.dropout)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "younger-classics",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 pretrained_embeddings_path,\n",
    "                 token_to_index,\n",
    "                 n_labels,\n",
    "                 hidden_layer=128,\n",
    "                 dropout=0.3,\n",
    "                 vector_size=300,\n",
    "                 num_layers=1,\n",
    "                 bias=True,\n",
    "                 bidirectional=False,\n",
    "                 freeze_embedings=True):\n",
    "        super().__init__()\n",
    "\n",
    "        with gzip.open(token_to_index, \"rt\") as fh:\n",
    "            token_to_index = json.load(fh)\n",
    "        embeddings_matrix = torch.randn(len(token_to_index), vector_size)\n",
    "        embeddings_matrix[0] = torch.zeros(vector_size)\n",
    "        with gzip.open(pretrained_embeddings_path, \"rt\") as fh:\n",
    "            next(fh)\n",
    "            for line in fh:\n",
    "                word, vector = line.strip().split(None, 1)\n",
    "                if word in token_to_index:\n",
    "                    embeddings_matrix[token_to_index[word]] =\\\n",
    "                        torch.FloatTensor([float(n) for n in vector.split()])\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n",
    "                                                       freeze=freeze_embedings,\n",
    "                                                       padding_idx=0)\n",
    "        # Set our LSTM parameters\n",
    "        self.lstm_config = {'input_size': vector_size,\n",
    "                            'hidden_size': hidden_layer,\n",
    "                            'num_layers': num_layers,\n",
    "                            'bias': bias,\n",
    "                            'batch_first': True,\n",
    "                            'dropout': dropout,\n",
    "                            'bidirectional': bidirectional}\n",
    "        if num_layers == 1: self.lstm_config['dropout']=0\n",
    "        # Set our FC layer parameters\n",
    "        self.linear_config = {'in_features': hidden_layer,\n",
    "                              'out_features': n_labels,\n",
    "                              'bias': bias}\n",
    "        \n",
    "        # Instanciate the layers\n",
    "        self.encoder = nn.LSTM(**self.lstm_config)\n",
    "        self.output = nn.Linear(hidden_layer, n_labels)\n",
    "        self.vector_size = vector_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        outputs, (ht, ct) = self.encoder(x)\n",
    "        predictions = self.output(ht[-1])\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 pretrained_embeddings_path, \n",
    "                 token_to_index,\n",
    "                 vector_size,\n",
    "                 n_labels,\n",
    "                 filter_count=100,\n",
    "                 filters_lenght=[2,3,4],\n",
    "                 freeze_embedings=True):\n",
    "        super().__init__()\n",
    "        with gzip.open(token_to_index, \"rt\") as fh:\n",
    "            token_to_index = json.load(fh)\n",
    "        embeddings_matrix = torch.randn(len(token_to_index), vector_size)\n",
    "        embeddings_matrix[0] = torch.zeros(vector_size)\n",
    "        with gzip.open(pretrained_embeddings_path, \"rt\") as fh:\n",
    "            next(fh)\n",
    "            for line in fh:\n",
    "                word, vector = line.strip().split(None, 1)\n",
    "                if word in token_to_index:\n",
    "                    embeddings_matrix[token_to_index[word]] =\\\n",
    "                        torch.FloatTensor([float(n) for n in vector.split()])\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n",
    "                                                       freeze=freeze_embedings,\n",
    "                                                       padding_idx=0)\n",
    "        self.convs = []\n",
    "        for filter_lenght in filters_length:\n",
    "            self.convs.append(\n",
    "                nn.Conv1d(vector_size, filters_count, filter_lenght)\n",
    "            )\n",
    "        self.convs = nn.ModuleList(self.convs)\n",
    "        self.fc = nn.Linear(filters_count * len(filters_length), 128)\n",
    "        self.output = nn.Linear(128, n_labels)\n",
    "        self.vector_size = vector_size\n",
    "    \n",
    "    @staticmethod\n",
    "    def conv_global_max_pool(x, conv):\n",
    "        return F.relu(conv(x).transpose(1, 2).max(1)[0])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x).transpose(1, 2)  # Conv1d takes (batch, channel, seq_len)\n",
    "        x = [self.conv_global_max_pool(x, conv) for conv in self.convs]\n",
    "        x = torch.cat(x, dim=1)\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pressed-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data='./data/meli-challenge-2019/spanish.train.jsonl.gz'\n",
    "test_data=''\n",
    "token_to_index='./data/meli-challenge-2019/spanish_token_to_index.json.gz'\n",
    "pretrained_embeddings='./data/SBW-vectors-300-min5.txt.gz'\n",
    "language='spanish'\n",
    "validation_data='./data/meli-challenge-2019/spanish.validation.jsonl.gz'\n",
    "embeddings_size=300\n",
    "hidden_layer=64\n",
    "num_layers=1\n",
    "dropout=0.3\n",
    "epochs=1\n",
    "bidirectional=True\n",
    "batch_size=128\n",
    "learning_rate=0.001\n",
    "weight_decay=0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "premium-repair",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-20 20:00:14,316: INFO - Building training dataset\n"
     ]
    }
   ],
   "source": [
    "pad_sequences = PadSequences(\n",
    "    pad_value=0,\n",
    "    max_length=None,\n",
    "    min_length=1\n",
    ")\n",
    "\n",
    "logging.info(\"Building training dataset\")\n",
    "train_dataset = MeliChallengeDataset(\n",
    "    dataset_path=train_data,\n",
    "    random_buffer_size=2048  # This can be a hypterparameter\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,  # This can be a hyperparameter\n",
    "    shuffle=False,\n",
    "    collate_fn=pad_sequences,\n",
    "    drop_last=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "flexible-serum",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-20 20:00:14,968: INFO - Building validation dataset\n"
     ]
    }
   ],
   "source": [
    "if validation_data:\n",
    "    logging.info(\"Building validation dataset\")\n",
    "    validation_dataset = MeliChallengeDataset(\n",
    "        dataset_path=validation_data,\n",
    "        random_buffer_size=1\n",
    "    )\n",
    "    validation_loader = DataLoader(\n",
    "        validation_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=pad_sequences,\n",
    "        drop_last=False\n",
    "    )\n",
    "else:\n",
    "    validation_dataset = None\n",
    "    validation_loader = None\n",
    "\n",
    "if test_data:\n",
    "    logging.info(\"Building test dataset\")\n",
    "    test_dataset = MeliChallengeDataset(\n",
    "        dataset_path=test_data,\n",
    "        random_buffer_size=1\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=pad_sequences,\n",
    "        drop_last=False\n",
    "    )\n",
    "else:\n",
    "    test_dataset = None\n",
    "    test_loader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "latest-watch",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-19 14:27:08,497: INFO - Starting experiment\n",
      "2021-03-19 14:27:08,531: INFO - Building classifier\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ef0c9193e40c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeddings_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfreeze_embedings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m  \u001b[0;31m# This can be a hyperparameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3c0c9fbc25d0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pretrained_embeddings_path, token_to_index, n_labels, hidden_layers, dropout, vector_size, freeze_embedings)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_embeddings_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken_to_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36mread1\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    494\u001b[0m                                \"end-of-stream marker was reached\")\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_read_data\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0muncompress\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muncompress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muncompress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deeplearning/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36m_add_read_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_read_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_crc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrc32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_crc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logging.info(\"Starting experiment\")\n",
    "# Log all relevent hyperparameters\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "logging.info(\"Building classifier\")\n",
    "model = MLPClassifier(\n",
    "    pretrained_embeddings_path=pretrained_embeddings,\n",
    "    token_to_index=token_to_index,\n",
    "    n_labels=train_dataset.n_labels,\n",
    "    hidden_layers=hidden_layers,\n",
    "    dropout=dropout,\n",
    "    vector_size=embeddings_size,\n",
    "    freeze_embedings=True  # This can be a hyperparameter\n",
    ")\n",
    "model = model.to(device)\n",
    "logging.info(model)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "logging.info(loss)\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,  # This can be a hyperparameter\n",
    "    weight_decay=weight_decay  # This can be a hyperparameter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aggregate-edinburgh",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-20 20:01:47,840: INFO - Starting experiment\n",
      "2021-03-20 20:01:47,842: INFO - Building classifier\n",
      "2021-03-20 20:02:17,499: INFO - RNNClassifier(\n",
      "  (embeddings): Embedding(50002, 300, padding_idx=0)\n",
      "  (encoder): LSTM(300, 64, batch_first=True, bidirectional=True)\n",
      "  (output): Linear(in_features=64, out_features=632, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n",
      "2021-03-20 20:02:17,501: INFO - CrossEntropyLoss()\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Starting experiment\")\n",
    "# Log all relevent hyperparameters\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "logging.info(\"Building classifier\")\n",
    "model = RNNClassifier(\n",
    "    pretrained_embeddings_path=pretrained_embeddings,\n",
    "    token_to_index=token_to_index,\n",
    "    n_labels=train_dataset.n_labels,\n",
    "    hidden_layer=hidden_layer,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    bidirectional=bidirectional,\n",
    "    vector_size=embeddings_size,\n",
    "    freeze_embedings=True  # This can be a hyperparameter\n",
    ")\n",
    "model = model.to(device)\n",
    "logging.info(model)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "logging.info(loss)\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,  # This can be a hyperparameter\n",
    "    weight_decay=weight_decay  # This can be a hyperparameter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "clear-dallas",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-20 20:02:38,883: INFO - Training classifier\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f18d75c12de47f3ba5cae4c4b44d589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c472fb7130cb4cbb993216de8d9d4903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logging.info(\"Training classifier\")\n",
    "model.train()\n",
    "for epoch in trange(epochs):\n",
    "    running_loss = []\n",
    "    for idx, batch in enumerate(tqdm(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        data = batch[\"data\"].to(device)\n",
    "        target = batch[\"target\"].to(device)\n",
    "        output = model(data)\n",
    "#        if idx % 1000 == 0 or idx == 1:\n",
    "#            logging.info(\n",
    "#                f\" data{data.shape}, target: {target.shape}, output: {output.shape}\"\n",
    "#            )\n",
    "        loss_value = loss(output, target)\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        running_loss.append(loss_value.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sustained-tournament",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-20 20:07:29,336: INFO - Evaluating model on validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca56f29ef64481081a11533595ea20f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if validation_dataset:\n",
    "    logging.info(\"Evaluating model on validation\")\n",
    "    model.eval()\n",
    "    running_loss = []\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(validation_loader):\n",
    "            data = batch[\"data\"].to(device)\n",
    "            target = batch[\"target\"].to(device)\n",
    "            output = model(data)\n",
    "            running_loss.append(\n",
    "                loss(output, target).item()\n",
    "            )\n",
    "            targets.extend(batch[\"target\"].numpy())\n",
    "            predictions.extend(output.argmax(axis=1).detach().cpu().numpy())\n",
    "        validation_loss=sum(running_loss) / len(running_loss)\n",
    "        validation_bacc=balanced_accuracy_score(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "filled-niagara",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0284787952652879"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_bacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "governing-trance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.31628486427446"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "weird-mason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[190.46923828125,\n",
       " 155.0888671875,\n",
       " 134.0845947265625,\n",
       " 119.7809066772461,\n",
       " 136.447998046875,\n",
       " 116.58866882324219,\n",
       " 152.62648010253906,\n",
       " 140.319091796875,\n",
       " 138.42308044433594,\n",
       " 109.41680145263672,\n",
       " 170.3216094970703,\n",
       " 118.48246765136719,\n",
       " 143.74794006347656,\n",
       " 157.5228729248047,\n",
       " 157.9416961669922,\n",
       " 171.3623809814453,\n",
       " 149.07916259765625,\n",
       " 139.8533935546875,\n",
       " 109.84098052978516,\n",
       " 119.46031188964844,\n",
       " 137.6290283203125,\n",
       " 164.5352783203125,\n",
       " 135.20913696289062,\n",
       " 133.97030639648438,\n",
       " 125.65333557128906,\n",
       " 113.91716003417969,\n",
       " 178.70547485351562,\n",
       " 126.47895812988281,\n",
       " 124.00418853759766,\n",
       " 176.83006286621094,\n",
       " 135.4651641845703,\n",
       " 134.6033935546875,\n",
       " 171.90615844726562,\n",
       " 158.7423095703125,\n",
       " 198.43368530273438,\n",
       " 146.71197509765625,\n",
       " 143.58074951171875,\n",
       " 165.2445068359375,\n",
       " 173.45611572265625,\n",
       " 150.12811279296875,\n",
       " 177.45472717285156,\n",
       " 183.646728515625,\n",
       " 176.5774688720703,\n",
       " 117.40399169921875,\n",
       " 153.33241271972656,\n",
       " 144.76148986816406,\n",
       " 155.33474731445312,\n",
       " 151.03268432617188,\n",
       " 172.53758239746094,\n",
       " 116.53852844238281,\n",
       " 163.9231414794922,\n",
       " 125.08464813232422,\n",
       " 190.4777069091797,\n",
       " 181.2418212890625,\n",
       " 152.91720581054688,\n",
       " 168.52838134765625,\n",
       " 152.8919677734375,\n",
       " 129.38888549804688,\n",
       " 174.9870147705078,\n",
       " 125.02496337890625,\n",
       " 157.2299346923828,\n",
       " 164.52896118164062,\n",
       " 135.12705993652344,\n",
       " 167.30795288085938,\n",
       " 151.9920654296875,\n",
       " 199.91871643066406,\n",
       " 165.29779052734375,\n",
       " 158.55972290039062,\n",
       " 132.69049072265625,\n",
       " 141.9851837158203,\n",
       " 160.19395446777344,\n",
       " 160.11912536621094,\n",
       " 159.0823211669922,\n",
       " 142.34518432617188,\n",
       " 182.07044982910156,\n",
       " 179.74798583984375,\n",
       " 142.61251831054688,\n",
       " 173.17242431640625,\n",
       " 144.84552001953125,\n",
       " 134.0458984375,\n",
       " 159.75442504882812,\n",
       " 163.77215576171875,\n",
       " 173.4697265625,\n",
       " 140.82876586914062,\n",
       " 139.5140838623047,\n",
       " 144.14109802246094,\n",
       " 163.32044982910156,\n",
       " 147.58334350585938,\n",
       " 167.44007873535156,\n",
       " 166.30487060546875,\n",
       " 206.88516235351562,\n",
       " 123.43140411376953,\n",
       " 135.62701416015625,\n",
       " 151.71067810058594,\n",
       " 132.92410278320312,\n",
       " 159.93212890625,\n",
       " 144.76165771484375,\n",
       " 119.94668579101562,\n",
       " 142.38829040527344,\n",
       " 147.3268280029297,\n",
       " 128.64601135253906,\n",
       " 185.29505920410156,\n",
       " 147.00498962402344,\n",
       " 108.23085021972656,\n",
       " 150.48074340820312,\n",
       " 144.44747924804688,\n",
       " 112.02348327636719,\n",
       " 137.28775024414062,\n",
       " 171.06858825683594,\n",
       " 175.08518981933594,\n",
       " 113.28382873535156,\n",
       " 138.26156616210938,\n",
       " 168.16946411132812,\n",
       " 150.9779815673828,\n",
       " 147.45761108398438,\n",
       " 152.1501007080078,\n",
       " 135.89967346191406,\n",
       " 177.40000915527344,\n",
       " 105.0678939819336,\n",
       " 143.05224609375,\n",
       " 173.80328369140625,\n",
       " 141.60354614257812,\n",
       " 164.91407775878906,\n",
       " 132.2857666015625,\n",
       " 178.54502868652344,\n",
       " 164.5107421875,\n",
       " 165.70770263671875,\n",
       " 174.37286376953125,\n",
       " 138.874755859375,\n",
       " 116.20672607421875,\n",
       " 144.2338104248047,\n",
       " 138.69435119628906,\n",
       " 143.5983428955078,\n",
       " 119.06187438964844,\n",
       " 178.3350830078125,\n",
       " 158.2727813720703,\n",
       " 157.94454956054688,\n",
       " 128.731201171875,\n",
       " 131.6692352294922,\n",
       " 127.31670379638672,\n",
       " 123.67462921142578,\n",
       " 113.4260482788086,\n",
       " 128.74404907226562,\n",
       " 150.9409637451172,\n",
       " 156.3492431640625,\n",
       " 152.4468231201172,\n",
       " 126.55338287353516,\n",
       " 190.3261260986328,\n",
       " 150.51480102539062,\n",
       " 125.45040130615234,\n",
       " 99.16838073730469,\n",
       " 166.38087463378906,\n",
       " 145.77838134765625,\n",
       " 135.12002563476562,\n",
       " 161.05380249023438,\n",
       " 131.1624298095703,\n",
       " 158.68887329101562,\n",
       " 111.69390869140625,\n",
       " 147.00729370117188,\n",
       " 155.03384399414062,\n",
       " 129.13760375976562,\n",
       " 185.52911376953125,\n",
       " 130.1190948486328,\n",
       " 149.43838500976562,\n",
       " 151.88241577148438,\n",
       " 151.47193908691406,\n",
       " 204.65383911132812,\n",
       " 135.67689514160156,\n",
       " 160.703369140625,\n",
       " 135.85580444335938,\n",
       " 131.99728393554688,\n",
       " 156.19546508789062,\n",
       " 151.4109649658203,\n",
       " 160.22720336914062,\n",
       " 147.21409606933594,\n",
       " 166.88998413085938,\n",
       " 126.21267700195312,\n",
       " 132.12814331054688,\n",
       " 140.59474182128906,\n",
       " 148.93431091308594,\n",
       " 142.29360961914062,\n",
       " 142.32940673828125,\n",
       " 134.66241455078125,\n",
       " 129.46609497070312,\n",
       " 129.5503692626953,\n",
       " 123.38587188720703,\n",
       " 112.15338897705078,\n",
       " 162.58921813964844,\n",
       " 127.72445678710938,\n",
       " 133.23892211914062,\n",
       " 171.9667510986328,\n",
       " 178.7992706298828,\n",
       " 127.3471908569336,\n",
       " 186.3076934814453,\n",
       " 132.17617797851562,\n",
       " 185.56967163085938,\n",
       " 162.07896423339844,\n",
       " 161.0821990966797,\n",
       " 153.431640625,\n",
       " 136.90982055664062,\n",
       " 129.3015594482422,\n",
       " 118.60234069824219,\n",
       " 146.82435607910156,\n",
       " 161.70570373535156,\n",
       " 117.09680938720703,\n",
       " 155.09710693359375,\n",
       " 106.6203842163086,\n",
       " 156.77061462402344,\n",
       " 154.64683532714844,\n",
       " 134.8166046142578,\n",
       " 129.3773193359375,\n",
       " 188.89988708496094,\n",
       " 165.4976348876953,\n",
       " 104.50920104980469,\n",
       " 184.08013916015625,\n",
       " 120.90354919433594,\n",
       " 151.4473114013672,\n",
       " 137.5539093017578,\n",
       " 164.43350219726562,\n",
       " 165.95509338378906,\n",
       " 163.59451293945312,\n",
       " 171.66226196289062,\n",
       " 141.51824951171875,\n",
       " 162.2466278076172,\n",
       " 103.98897552490234,\n",
       " 143.73394775390625,\n",
       " 160.66241455078125,\n",
       " 162.8865203857422,\n",
       " 191.6096649169922,\n",
       " 172.0994873046875,\n",
       " 156.8685302734375,\n",
       " 128.51840209960938,\n",
       " 136.9947967529297,\n",
       " 169.07757568359375,\n",
       " 144.14178466796875,\n",
       " 176.74493408203125,\n",
       " 145.93600463867188,\n",
       " 117.48037719726562,\n",
       " 136.23460388183594,\n",
       " 162.59957885742188,\n",
       " 144.8087921142578,\n",
       " 161.64222717285156,\n",
       " 119.60835266113281,\n",
       " 142.58004760742188,\n",
       " 209.63568115234375,\n",
       " 160.7996368408203,\n",
       " 115.87733459472656,\n",
       " 191.50360107421875,\n",
       " 151.7718048095703,\n",
       " 110.3350601196289,\n",
       " 159.13284301757812,\n",
       " 133.8277587890625,\n",
       " 206.16033935546875,\n",
       " 134.8675079345703,\n",
       " 123.2728500366211,\n",
       " 213.65982055664062,\n",
       " 170.95130920410156,\n",
       " 184.6999053955078,\n",
       " 134.9619598388672,\n",
       " 143.8805389404297,\n",
       " 142.4309539794922,\n",
       " 152.83836364746094,\n",
       " 120.29150390625,\n",
       " 169.63858032226562,\n",
       " 128.8985137939453,\n",
       " 106.71466064453125,\n",
       " 141.7567138671875,\n",
       " 148.91993713378906,\n",
       " 145.0033416748047,\n",
       " 98.94153594970703,\n",
       " 132.45703125,\n",
       " 120.70055389404297,\n",
       " 159.56040954589844,\n",
       " 135.9661407470703,\n",
       " 123.6637191772461,\n",
       " 129.7633514404297,\n",
       " 127.40711975097656,\n",
       " 121.75731658935547,\n",
       " 175.666748046875,\n",
       " 139.88119506835938,\n",
       " 146.36146545410156,\n",
       " 203.42234802246094,\n",
       " 137.95436096191406,\n",
       " 171.13250732421875,\n",
       " 169.38790893554688,\n",
       " 164.8262176513672,\n",
       " 143.07772827148438,\n",
       " 165.00100708007812,\n",
       " 205.9139404296875,\n",
       " 165.8666534423828,\n",
       " 138.71401977539062,\n",
       " 139.89244079589844,\n",
       " 175.06739807128906,\n",
       " 170.46746826171875,\n",
       " 121.38733673095703,\n",
       " 136.75738525390625,\n",
       " 125.8998794555664,\n",
       " 139.8516082763672,\n",
       " 146.6481475830078,\n",
       " 149.92945861816406,\n",
       " 141.40480041503906,\n",
       " 205.7250213623047,\n",
       " 153.79464721679688,\n",
       " 158.1298065185547,\n",
       " 183.27981567382812,\n",
       " 148.5071258544922,\n",
       " 146.8512420654297,\n",
       " 122.14995574951172,\n",
       " 138.88392639160156,\n",
       " 172.43218994140625,\n",
       " 135.20872497558594,\n",
       " 144.5791473388672,\n",
       " 125.71650695800781,\n",
       " 178.9027557373047,\n",
       " 169.24539184570312,\n",
       " 133.89344787597656,\n",
       " 113.8182373046875,\n",
       " 152.3759307861328,\n",
       " 136.336669921875,\n",
       " 129.08457946777344,\n",
       " 147.45216369628906,\n",
       " 145.1691436767578,\n",
       " 173.67572021484375,\n",
       " 167.0340576171875,\n",
       " 170.78329467773438,\n",
       " 154.71669006347656,\n",
       " 196.13565063476562,\n",
       " 146.94778442382812,\n",
       " 155.75718688964844,\n",
       " 136.51121520996094,\n",
       " 148.159912109375,\n",
       " 125.12879180908203,\n",
       " 132.1533203125,\n",
       " 133.76470947265625,\n",
       " 131.91529846191406,\n",
       " 128.07989501953125,\n",
       " 151.90000915527344,\n",
       " 155.93588256835938,\n",
       " 172.29519653320312,\n",
       " 138.39035034179688,\n",
       " 210.6732940673828,\n",
       " 136.2502899169922,\n",
       " 168.36758422851562,\n",
       " 159.85887145996094,\n",
       " 142.76004028320312,\n",
       " 124.44642639160156,\n",
       " 153.43980407714844,\n",
       " 100.46357727050781,\n",
       " 199.86070251464844,\n",
       " 145.01287841796875,\n",
       " 183.56295776367188,\n",
       " 145.88441467285156,\n",
       " 142.1549072265625,\n",
       " 153.1195068359375,\n",
       " 186.4088592529297,\n",
       " 103.48983001708984,\n",
       " 187.5010223388672,\n",
       " 142.1136016845703,\n",
       " 149.63967895507812,\n",
       " 150.7317657470703,\n",
       " 136.7084197998047,\n",
       " 153.86569213867188,\n",
       " 163.7425079345703,\n",
       " 130.39036560058594,\n",
       " 144.9036102294922,\n",
       " 149.38917541503906,\n",
       " 155.26702880859375,\n",
       " 127.362548828125,\n",
       " 122.30043029785156,\n",
       " 164.45623779296875,\n",
       " 158.4847869873047,\n",
       " 164.09661865234375,\n",
       " 144.4339599609375,\n",
       " 141.03814697265625,\n",
       " 128.1566619873047,\n",
       " 123.63772583007812,\n",
       " 144.913330078125,\n",
       " 192.33935546875,\n",
       " 184.1028594970703,\n",
       " 149.44375610351562,\n",
       " 161.52569580078125,\n",
       " 145.57884216308594,\n",
       " 154.9072265625,\n",
       " 176.0614013671875,\n",
       " 138.6048583984375,\n",
       " 156.36746215820312,\n",
       " 136.25921630859375,\n",
       " 170.65773010253906,\n",
       " 96.05741882324219,\n",
       " 104.94001007080078,\n",
       " 154.41624450683594,\n",
       " 153.162841796875,\n",
       " 133.63787841796875,\n",
       " 166.14361572265625,\n",
       " 156.15870666503906,\n",
       " 154.69064331054688,\n",
       " 134.37257385253906,\n",
       " 208.74911499023438,\n",
       " 128.00489807128906,\n",
       " 90.78063201904297,\n",
       " 147.81117248535156,\n",
       " 119.35386657714844,\n",
       " 135.79684448242188,\n",
       " 149.8198699951172,\n",
       " 167.6066436767578,\n",
       " 155.78384399414062,\n",
       " 176.19891357421875,\n",
       " 144.9900360107422,\n",
       " 140.24342346191406,\n",
       " 170.761474609375,\n",
       " 165.16189575195312,\n",
       " 144.13955688476562,\n",
       " 149.94908142089844,\n",
       " 166.99403381347656,\n",
       " 139.86761474609375,\n",
       " 159.94009399414062,\n",
       " 133.65370178222656,\n",
       " 123.31909942626953,\n",
       " 145.79493713378906,\n",
       " 135.60218811035156,\n",
       " 143.33782958984375,\n",
       " 174.7686004638672,\n",
       " 137.9482879638672,\n",
       " 128.38504028320312,\n",
       " 148.68983459472656,\n",
       " 129.6019287109375,\n",
       " 169.03753662109375,\n",
       " 146.8480224609375,\n",
       " 141.60498046875,\n",
       " 131.99554443359375,\n",
       " 118.08812713623047,\n",
       " 125.53175354003906,\n",
       " 126.54190826416016,\n",
       " 169.513916015625,\n",
       " 154.3391876220703,\n",
       " 145.4868927001953,\n",
       " 192.64932250976562,\n",
       " 185.16958618164062,\n",
       " 165.653076171875,\n",
       " 160.75576782226562,\n",
       " 160.9487762451172,\n",
       " 156.30361938476562,\n",
       " 169.66165161132812,\n",
       " 158.90228271484375,\n",
       " 150.01153564453125,\n",
       " 165.19021606445312,\n",
       " 163.37156677246094,\n",
       " 152.90335083007812,\n",
       " 102.16876220703125,\n",
       " 171.12619018554688,\n",
       " 159.8743133544922,\n",
       " 178.77467346191406,\n",
       " 142.4936065673828,\n",
       " 174.30137634277344,\n",
       " 142.68443298339844,\n",
       " 118.2371597290039,\n",
       " 165.5386962890625,\n",
       " 122.16686248779297,\n",
       " 144.9921875,\n",
       " 135.31849670410156,\n",
       " 173.47906494140625,\n",
       " 125.0234375,\n",
       " 159.15423583984375,\n",
       " 152.45481872558594,\n",
       " 150.63218688964844,\n",
       " 162.0623016357422,\n",
       " 122.42289733886719,\n",
       " 144.484130859375,\n",
       " 172.78204345703125,\n",
       " 119.43183898925781,\n",
       " 136.70106506347656,\n",
       " 160.7029571533203,\n",
       " 118.56511688232422,\n",
       " 125.74969482421875,\n",
       " 171.69451904296875,\n",
       " 136.64349365234375,\n",
       " 140.4751434326172,\n",
       " 168.07806396484375,\n",
       " 130.16624450683594,\n",
       " 135.41366577148438,\n",
       " 132.99685668945312,\n",
       " 191.18930053710938,\n",
       " 180.31768798828125,\n",
       " 146.73455810546875,\n",
       " 152.438720703125,\n",
       " 143.3529510498047,\n",
       " 146.8377227783203,\n",
       " 147.82131958007812,\n",
       " 134.3883056640625,\n",
       " 178.7762451171875,\n",
       " 169.16275024414062,\n",
       " 119.81351470947266,\n",
       " 142.11602783203125,\n",
       " 121.12706756591797,\n",
       " 135.79888916015625,\n",
       " 118.50970458984375,\n",
       " 138.18511962890625,\n",
       " 149.04501342773438,\n",
       " 184.8172607421875,\n",
       " 134.6135711669922,\n",
       " 126.24969482421875,\n",
       " 122.72728729248047,\n",
       " 104.04347229003906,\n",
       " 117.75016021728516,\n",
       " 210.80075073242188,\n",
       " 105.06515502929688,\n",
       " 151.43067932128906,\n",
       " 163.68519592285156,\n",
       " 165.384765625,\n",
       " 143.5832977294922,\n",
       " 141.1800994873047,\n",
       " 149.5301055908203,\n",
       " 167.06689453125,\n",
       " 149.9375457763672,\n",
       " 143.04983520507812,\n",
       " 160.3782501220703,\n",
       " 121.79488372802734,\n",
       " 126.72124481201172,\n",
       " 117.31856536865234,\n",
       " 151.17330932617188,\n",
       " 128.18502807617188,\n",
       " 145.78427124023438,\n",
       " 175.36627197265625,\n",
       " 190.9202423095703,\n",
       " 128.43246459960938,\n",
       " 186.41485595703125,\n",
       " 164.95889282226562,\n",
       " 161.02110290527344,\n",
       " 141.182373046875,\n",
       " 209.17166137695312,\n",
       " 115.16443634033203,\n",
       " 166.82667541503906,\n",
       " 143.83251953125,\n",
       " 181.82106018066406,\n",
       " 153.9910430908203,\n",
       " 140.69735717773438,\n",
       " 133.8848114013672,\n",
       " 125.34468841552734,\n",
       " 127.32695007324219,\n",
       " 177.33993530273438,\n",
       " 170.19830322265625,\n",
       " 147.09742736816406,\n",
       " 125.122802734375,\n",
       " 133.41494750976562,\n",
       " 142.8057098388672,\n",
       " 179.17156982421875,\n",
       " 139.29331970214844,\n",
       " 131.27243041992188,\n",
       " 171.46481323242188,\n",
       " 204.2047119140625,\n",
       " 131.16885375976562,\n",
       " 130.32371520996094,\n",
       " 157.00753784179688,\n",
       " 135.2602081298828,\n",
       " 123.51264953613281,\n",
       " 150.77735900878906,\n",
       " 121.14247131347656,\n",
       " 144.82875061035156,\n",
       " 125.45592498779297,\n",
       " 127.20932006835938,\n",
       " 128.6975555419922,\n",
       " 172.3302459716797,\n",
       " 132.11102294921875,\n",
       " 178.86715698242188,\n",
       " 115.4123306274414,\n",
       " 131.0775604248047,\n",
       " 153.44979858398438,\n",
       " 140.42262268066406,\n",
       " 182.74476623535156,\n",
       " 146.46826171875,\n",
       " 139.9235076904297,\n",
       " 123.03424072265625,\n",
       " 92.41838073730469,\n",
       " 155.0269317626953,\n",
       " 163.90542602539062,\n",
       " 142.40005493164062,\n",
       " 152.1006317138672,\n",
       " 148.18861389160156,\n",
       " 133.93763732910156,\n",
       " 160.83567810058594,\n",
       " 176.34112548828125,\n",
       " 134.3372802734375,\n",
       " 165.64862060546875,\n",
       " 157.7017364501953,\n",
       " 133.20494079589844,\n",
       " 153.80007934570312,\n",
       " 132.54220581054688,\n",
       " 133.24342346191406,\n",
       " 113.58567810058594,\n",
       " 140.14886474609375,\n",
       " 159.48573303222656,\n",
       " 160.8838348388672,\n",
       " 158.32803344726562,\n",
       " 119.70942687988281,\n",
       " 190.14549255371094,\n",
       " 144.71710205078125,\n",
       " 168.79559326171875,\n",
       " 155.23146057128906,\n",
       " 132.89697265625,\n",
       " 147.6741180419922,\n",
       " 132.30215454101562,\n",
       " 121.56169128417969,\n",
       " 169.4208526611328,\n",
       " 127.33125305175781,\n",
       " 175.75526428222656,\n",
       " 103.82101440429688,\n",
       " 107.39608764648438,\n",
       " 130.0496826171875,\n",
       " 174.66928100585938,\n",
       " 160.1655731201172,\n",
       " 133.1415557861328,\n",
       " 154.61387634277344,\n",
       " 129.5897674560547,\n",
       " 129.61260986328125,\n",
       " 155.85049438476562,\n",
       " 113.04110717773438,\n",
       " 129.50634765625,\n",
       " 166.43231201171875,\n",
       " 149.85791015625,\n",
       " 148.20819091796875,\n",
       " 176.18881225585938,\n",
       " 165.51263427734375,\n",
       " 160.90780639648438,\n",
       " 148.7158203125,\n",
       " 155.9956817626953,\n",
       " 127.64207458496094,\n",
       " 125.0562973022461,\n",
       " 121.56550598144531,\n",
       " 130.3143768310547,\n",
       " 140.7115478515625,\n",
       " 131.47003173828125,\n",
       " 114.76639556884766,\n",
       " 175.0364532470703,\n",
       " 143.5760955810547,\n",
       " 156.60061645507812,\n",
       " 122.8175048828125,\n",
       " 147.36343383789062,\n",
       " 156.25576782226562,\n",
       " 154.5609893798828,\n",
       " 158.03504943847656,\n",
       " 139.6522216796875,\n",
       " 123.23631286621094,\n",
       " 181.05833435058594,\n",
       " 166.6282958984375,\n",
       " 129.64459228515625,\n",
       " 136.02061462402344,\n",
       " 133.0291748046875,\n",
       " 175.25775146484375,\n",
       " 155.10501098632812,\n",
       " 136.843017578125,\n",
       " 121.00535583496094,\n",
       " 146.8131103515625,\n",
       " 170.60499572753906,\n",
       " 154.08154296875,\n",
       " 148.2718963623047,\n",
       " 161.0791473388672,\n",
       " 141.6524658203125,\n",
       " 156.36361694335938,\n",
       " 177.59095764160156,\n",
       " 191.06900024414062,\n",
       " 162.13104248046875,\n",
       " 144.84361267089844,\n",
       " 178.081787109375,\n",
       " 143.58624267578125,\n",
       " 138.421875,\n",
       " 136.36383056640625,\n",
       " 150.65789794921875,\n",
       " 134.07473754882812,\n",
       " 141.075927734375,\n",
       " 161.98973083496094,\n",
       " 169.50619506835938,\n",
       " 208.4248046875,\n",
       " 173.21255493164062,\n",
       " 130.0596466064453,\n",
       " 169.85964965820312,\n",
       " 189.8700714111328,\n",
       " 110.21318054199219,\n",
       " 159.23011779785156,\n",
       " 172.21490478515625,\n",
       " 145.01454162597656,\n",
       " 158.15097045898438,\n",
       " 191.856201171875,\n",
       " 179.19712829589844,\n",
       " 141.240234375,\n",
       " 114.738525390625,\n",
       " 157.31712341308594,\n",
       " 141.97616577148438,\n",
       " 127.28507995605469,\n",
       " 142.40142822265625,\n",
       " 174.36474609375,\n",
       " 165.16329956054688,\n",
       " 101.76585388183594,\n",
       " 151.81063842773438,\n",
       " 168.2508544921875,\n",
       " 183.15097045898438,\n",
       " 141.364990234375,\n",
       " 170.9455108642578,\n",
       " 128.05374145507812,\n",
       " 131.5301971435547,\n",
       " 123.77678680419922,\n",
       " 133.68141174316406,\n",
       " 148.7665252685547,\n",
       " 140.3330078125,\n",
       " 157.02223205566406,\n",
       " 159.33792114257812,\n",
       " 128.67308044433594,\n",
       " 152.2097930908203,\n",
       " 144.14219665527344,\n",
       " 167.00221252441406,\n",
       " 171.408935546875,\n",
       " 175.45643615722656,\n",
       " 191.304931640625,\n",
       " 157.47216796875,\n",
       " 116.2884521484375,\n",
       " 130.24301147460938,\n",
       " 188.3203125,\n",
       " 144.1890869140625,\n",
       " 105.9494400024414,\n",
       " 130.9297332763672,\n",
       " 157.90341186523438,\n",
       " 119.45130157470703,\n",
       " 171.7252960205078,\n",
       " 180.4265594482422,\n",
       " 146.34890747070312,\n",
       " 136.71592712402344,\n",
       " 95.8921127319336,\n",
       " 151.32266235351562,\n",
       " 140.38211059570312,\n",
       " 159.52792358398438,\n",
       " 200.9683380126953,\n",
       " 132.59774780273438,\n",
       " 127.30345916748047,\n",
       " 182.47093200683594,\n",
       " 171.4609375,\n",
       " 138.24673461914062,\n",
       " 149.1116485595703,\n",
       " 147.64833068847656,\n",
       " 184.3462677001953,\n",
       " 121.74337005615234,\n",
       " 173.22865295410156,\n",
       " 183.1328887939453,\n",
       " 120.83819580078125,\n",
       " 133.63983154296875,\n",
       " 137.07159423828125,\n",
       " 127.96546936035156,\n",
       " 158.72430419921875,\n",
       " 149.07135009765625,\n",
       " 169.0101776123047,\n",
       " 172.86766052246094,\n",
       " 172.1300506591797,\n",
       " 166.5175018310547,\n",
       " 155.42230224609375,\n",
       " 173.47840881347656,\n",
       " 136.39857482910156,\n",
       " 120.48018646240234,\n",
       " 164.35897827148438,\n",
       " 140.15748596191406,\n",
       " 150.224853515625,\n",
       " 156.22573852539062,\n",
       " 151.92379760742188,\n",
       " 163.4586944580078,\n",
       " 153.19601440429688,\n",
       " 122.03772735595703,\n",
       " 130.23194885253906,\n",
       " 97.87474060058594,\n",
       " 143.4052734375,\n",
       " 163.25946044921875,\n",
       " 76.00716400146484,\n",
       " 150.9061279296875,\n",
       " 175.689453125,\n",
       " 161.26058959960938,\n",
       " 118.69026184082031,\n",
       " 148.43443298339844,\n",
       " 139.79833984375,\n",
       " 115.05901336669922,\n",
       " 141.71182250976562,\n",
       " 177.91383361816406,\n",
       " 149.56809997558594,\n",
       " 159.15567016601562,\n",
       " 145.7339630126953,\n",
       " 117.12631225585938,\n",
       " 174.72149658203125,\n",
       " 139.4958953857422,\n",
       " 117.87281036376953,\n",
       " 140.30386352539062,\n",
       " 126.37633514404297,\n",
       " 138.5717010498047,\n",
       " 150.3166046142578,\n",
       " 133.39492797851562,\n",
       " 150.23834228515625,\n",
       " 142.36080932617188,\n",
       " 147.2675018310547,\n",
       " 153.48095703125,\n",
       " 92.79125213623047,\n",
       " 166.37448120117188,\n",
       " 151.542236328125,\n",
       " 154.1459503173828,\n",
       " 183.82989501953125,\n",
       " 133.86627197265625,\n",
       " 153.2384796142578,\n",
       " 170.69802856445312,\n",
       " 114.58786010742188,\n",
       " 159.77894592285156,\n",
       " 152.234619140625,\n",
       " 148.1021728515625,\n",
       " 125.21564483642578,\n",
       " 198.43141174316406,\n",
       " 168.4765167236328,\n",
       " 136.22572326660156,\n",
       " 213.8458709716797,\n",
       " 152.26800537109375,\n",
       " 183.85995483398438,\n",
       " 114.14815521240234,\n",
       " 150.60105895996094,\n",
       " 179.58660888671875,\n",
       " 134.61692810058594,\n",
       " 131.05140686035156,\n",
       " 134.51025390625,\n",
       " 103.05828857421875,\n",
       " 153.50135803222656,\n",
       " 160.05419921875,\n",
       " 120.23048400878906,\n",
       " 179.49078369140625,\n",
       " 110.09809112548828,\n",
       " 121.28802490234375,\n",
       " 152.03993225097656,\n",
       " 162.40090942382812,\n",
       " 166.17123413085938,\n",
       " 130.33970642089844,\n",
       " 133.97149658203125,\n",
       " 162.8893280029297,\n",
       " 157.72898864746094,\n",
       " 136.69638061523438,\n",
       " 136.7736358642578,\n",
       " 151.62608337402344,\n",
       " 148.34811401367188,\n",
       " 126.3641586303711,\n",
       " 125.42759704589844,\n",
       " 161.20999145507812,\n",
       " 121.09886169433594,\n",
       " 105.76776123046875,\n",
       " 191.70945739746094,\n",
       " 183.30311584472656,\n",
       " 173.69635009765625,\n",
       " 141.41812133789062,\n",
       " 144.2616424560547,\n",
       " 127.50215911865234,\n",
       " 147.54266357421875,\n",
       " 158.22125244140625,\n",
       " 143.20516967773438,\n",
       " 170.6155548095703,\n",
       " 130.85035705566406,\n",
       " 155.64605712890625,\n",
       " 141.46820068359375,\n",
       " 131.27392578125,\n",
       " 158.31521606445312,\n",
       " 166.59054565429688,\n",
       " 168.86776733398438,\n",
       " 145.546630859375,\n",
       " 149.9483184814453,\n",
       " 172.83348083496094,\n",
       " 165.85934448242188,\n",
       " 123.09217834472656,\n",
       " 142.99444580078125,\n",
       " 155.6233673095703,\n",
       " 152.8611297607422,\n",
       " 176.75112915039062,\n",
       " 148.78912353515625,\n",
       " 161.0140380859375,\n",
       " 142.360107421875,\n",
       " 158.86585998535156,\n",
       " 165.7805633544922,\n",
       " 114.23883056640625,\n",
       " 163.6800537109375,\n",
       " 176.0960693359375,\n",
       " 164.39089965820312,\n",
       " 162.51686096191406,\n",
       " 149.96267700195312,\n",
       " 162.97634887695312,\n",
       " 113.60633850097656,\n",
       " 131.73330688476562,\n",
       " 174.6573486328125,\n",
       " 150.8948974609375,\n",
       " 113.7742691040039,\n",
       " 156.22450256347656,\n",
       " 132.17034912109375,\n",
       " 135.26036071777344,\n",
       " 117.30863189697266,\n",
       " 154.40618896484375,\n",
       " 139.6138916015625,\n",
       " 149.02719116210938,\n",
       " 183.93331909179688,\n",
       " 188.877197265625,\n",
       " 164.3480682373047,\n",
       " 136.38182067871094,\n",
       " 100.7685546875,\n",
       " 151.1078338623047,\n",
       " 130.53369140625,\n",
       " 165.8274383544922,\n",
       " 110.02190399169922,\n",
       " 115.24835205078125,\n",
       " 191.82691955566406,\n",
       " 119.53202819824219,\n",
       " 138.222900390625,\n",
       " 129.3481903076172,\n",
       " 152.10574340820312,\n",
       " 141.10682678222656,\n",
       " 159.48574829101562,\n",
       " 179.34072875976562,\n",
       " 151.85801696777344,\n",
       " 150.0849609375,\n",
       " 176.29913330078125,\n",
       " 144.44265747070312,\n",
       " 122.03433227539062,\n",
       " 171.18118286132812,\n",
       " 151.93768310546875,\n",
       " 132.60411071777344,\n",
       " 135.543212890625,\n",
       " 129.48983764648438,\n",
       " 141.330810546875,\n",
       " 155.23272705078125,\n",
       " 207.88906860351562,\n",
       " 172.38247680664062,\n",
       " 144.34632873535156,\n",
       " 153.9758758544922,\n",
       " 164.6625213623047,\n",
       " 152.6193389892578,\n",
       " 132.47666931152344,\n",
       " 144.9718017578125,\n",
       " 139.01661682128906,\n",
       " 171.50550842285156,\n",
       " 115.36900329589844,\n",
       " 142.0043182373047,\n",
       " 164.19789123535156,\n",
       " 165.441650390625,\n",
       " 175.51797485351562,\n",
       " 172.26478576660156,\n",
       " 146.6192169189453,\n",
       " 121.00293731689453,\n",
       " 131.01429748535156,\n",
       " 132.62704467773438,\n",
       " 153.09510803222656,\n",
       " 158.33261108398438,\n",
       " 102.29776000976562,\n",
       " 161.39317321777344,\n",
       " 155.30860900878906,\n",
       " 163.45318603515625,\n",
       " 119.97000885009766,\n",
       " 140.35311889648438,\n",
       " 189.1240692138672,\n",
       " 126.23435974121094,\n",
       " 170.50303649902344,\n",
       " 156.86251831054688,\n",
       " 104.6563491821289,\n",
       " 161.79495239257812,\n",
       " 131.18344116210938,\n",
       " 158.20863342285156,\n",
       " 138.35531616210938,\n",
       " 142.3629608154297,\n",
       " 172.64268493652344,\n",
       " 147.62255859375,\n",
       " 159.32594299316406,\n",
       " 140.365966796875,\n",
       " 126.8258285522461,\n",
       " 144.6905059814453,\n",
       " 168.3391876220703,\n",
       " 167.13497924804688,\n",
       " 144.86871337890625,\n",
       " 130.99362182617188,\n",
       " 151.84181213378906,\n",
       " 179.4764862060547,\n",
       " 144.9770965576172,\n",
       " 146.83346557617188,\n",
       " 182.5010223388672,\n",
       " 143.8380889892578,\n",
       " 109.97227478027344,\n",
       " 152.12216186523438,\n",
       " 154.20323181152344,\n",
       " 131.62440490722656,\n",
       " 180.82147216796875,\n",
       " 167.33770751953125,\n",
       " 185.7001495361328,\n",
       " 134.99240112304688,\n",
       " 97.2965316772461,\n",
       " 141.1925811767578,\n",
       " 147.98939514160156,\n",
       " 127.75804138183594,\n",
       " 158.63201904296875,\n",
       " 167.60238647460938,\n",
       " 130.89520263671875,\n",
       " 145.1482391357422,\n",
       " 131.20718383789062,\n",
       " 132.7782745361328,\n",
       " 131.7631378173828,\n",
       " 144.79159545898438,\n",
       " 123.67375946044922,\n",
       " 136.7250213623047,\n",
       " 163.73513793945312,\n",
       " 149.02880859375,\n",
       " 190.43873596191406,\n",
       " ...]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-domestic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
